# Game Bug Report Classifier & Triage System

> Fine-tuning a Large Language Model for intelligent bug report classification and developer triage

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ Project Overview

This project fine-tunes a pre-trained Large Language Model to automatically classify and triage game bug reports. The system performs multiple tasks:

- **Severity Classification**: Critical, High, Medium, Low
- **Component Detection**: UI, Gameplay, Audio, Graphics, Network, etc.
- **Reproducibility Assessment**: Always, Sometimes, Rare
- **Developer Summary Generation**: Concise, actionable bug descriptions

### Real-World Impact
Game studios receive thousands of bug reports daily. This system can:
- Save developer time by automatically triaging reports
- Prioritize critical bugs for faster resolution
- Standardize bug report quality across platforms
- Surface patterns in recurring issues

## ğŸš€ Quick Start

### Environment Setup

**Requirements:**
- Python 3.8+
- CUDA-capable GPU (12GB+ VRAM recommended, or use Kaggle with 2Ã— Tesla T4)
- 20GB disk space for model weights

**Installation:**

```bash
# Clone the repository
git clone <your-repo-url>
cd "LLM Fine Tuning"

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Alternative: Install from requirements
pip install torch transformers peft bitsandbytes datasets accelerate tqdm
```

**Kaggle Setup (Recommended for Training):**
1. Create new Kaggle notebook
2. Enable GPU (Settings â†’ Accelerator â†’ GPU T4 x2)
3. Upload data splits as Kaggle dataset
4. Run: `!pip install transformers peft bitsandbytes accelerate`
5. Clone your repo or upload scripts directly

### Running the Demo

```bash
# Interactive classification demo
python scripts/demo.py --model_path final_model/ --mode interactive

# Pre-loaded examples
python scripts/demo.py --model_path final_model/ --mode examples

# Batch mode for video recording
python scripts/demo.py --model_path final_model/ --mode batch
```

### Training

```bash
# Train model with default hyperparameters (r=8, Î±=32)
python scripts/train.py \
    --train_path data/train_improved.jsonl \
    --val_path data/val.jsonl \
    --output_dir outputs/final_model \
    --num_epochs 3 \
    --batch_size 4 \
    --learning_rate 2e-4

# Train with custom LoRA rank (for hyperparameter optimization)
python scripts/train.py \
    --train_path data/train_improved.jsonl \
    --val_path data/val.jsonl \
    --output_dir outputs/model_r16 \
    --lora_r 16 \
    --lora_alpha 64
```

### Evaluation

```bash
# Evaluate fine-tuned model
python scripts/evaluate.py \
    --model_path final_model/ \
    --test_path data/test.jsonl \
    --num_samples 100

# Evaluate zero-shot baseline (no fine-tuning)
python scripts/evaluate_baseline.py \
    --model_name mistralai/Mistral-7B-Instruct-v0.2 \
    --test_path data/test.jsonl \
    --num_samples 100
```

## ğŸ—ï¸ Project Structure

```
.
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.py                   # Package installation
â”œâ”€â”€ .env.example               # Example environment variables
â”œâ”€â”€ .gitignore                 # Git ignore patterns
â”‚
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml      # Model hyperparameters
â”‚   â”œâ”€â”€ training_config.yaml   # Training settings
â”‚   â””â”€â”€ data_config.yaml       # Data processing config
â”‚
â”œâ”€â”€ data/                      # Data directory (gitignored)
â”‚   â”œâ”€â”€ raw/                   # Original bug reports
â”‚   â”œâ”€â”€ processed/             # Cleaned and formatted data
â”‚   â”œâ”€â”€ splits/                # Train/val/test splits
â”‚   â””â”€â”€ sample/                # Sample data for testing
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                  # Data processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ collectors.py      # Data collection scripts
â”‚   â”‚   â”œâ”€â”€ preprocessors.py   # Data cleaning
â”‚   â”‚   â””â”€â”€ formatters.py      # Format for fine-tuning
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Model code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py           # Model architecture
â”‚   â”‚   â””â”€â”€ trainer.py         # Training logic
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/            # Evaluation code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py         # Custom metrics
â”‚   â”‚   â””â”€â”€ evaluator.py       # Evaluation pipeline
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py          # Logging setup
â”‚       â””â”€â”€ helpers.py         # Helper functions
â”‚
â”œâ”€â”€ scripts/                   # Executable scripts
â”‚   â”œâ”€â”€ collect_data.py        # Data collection
â”‚   â”œâ”€â”€ preprocess_data.py     # Data preprocessing
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â”œâ”€â”€ evaluate.py            # Evaluation script
â”‚   â””â”€â”€ inference.py           # Inference/demo script
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_selection.ipynb
â”‚   â”œâ”€â”€ 03_error_analysis.ipynb
â”‚   â””â”€â”€ 04_results_visualization.ipynb
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_evaluation.py
â”‚
â”œâ”€â”€ models/                    # Saved models (gitignored)
â”‚   â”œâ”€â”€ base/                  # Pre-trained models
â”‚   â”œâ”€â”€ checkpoints/           # Training checkpoints
â”‚   â””â”€â”€ final/                 # Final fine-tuned models
â”‚
â”œâ”€â”€ outputs/                   # Results and logs (gitignored)
â”‚   â”œâ”€â”€ logs/                  # Training logs
â”‚   â”œâ”€â”€ results/               # Evaluation results
â”‚   â””â”€â”€ predictions/           # Model predictions
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ SETUP.md               # Setup instructions
    â”œâ”€â”€ METHODOLOGY.md         # Approach and methodology
    â”œâ”€â”€ RESULTS.md             # Results and analysis
    â””â”€â”€ API.md                 # API documentation
